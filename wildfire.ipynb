{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "import urllib.request\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from tfrecord.torch.dataset import MultiTFRecordDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-09T22:47:41.230097398Z",
     "start_time": "2024-12-09T22:47:41.173250489Z"
    }
   },
   "id": "d1f9e18237e3700e",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(in_channels=24, out_channels=1, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Upsample(64),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=4096, out_features=4096),\n",
    "            nn.Unflatten(1, (64, 64)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x).unsqueeze(1)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebc71bbfdb96edac"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Reshape(torch.nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)\n",
    "\n",
    "\n",
    "class ConvoAE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvoAE, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(12, 24, 3, 1, 1),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(24, 24, 3, 1, 0),  # 32 x 32 -> 30 x 30\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv2d(24, 32, 3, 2, 0),  # 30 x 30 -> 14 x 14\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv2d(32, 32, 3, 2, 0),  # 14 x 14 -> 6 x 6\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1152, 2),  # 1152 = 32 * 6  * 6\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 1152),\n",
    "            Reshape(-1, 32, 6, 6),\n",
    "            nn.ConvTranspose2d(32, 32, 3, 1, 0),  # 6 x 6 -> 8 x 8\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.ConvTranspose2d(32, 16, 3, 2, 1),  # 8 x 8 -> 15 x 15\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.ConvTranspose2d(16, 16, 3, 2, 0),  # 15 x 15 -> 31 x 31\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.ConvTranspose2d(16, 8, 3, 1, 0),  # 31 x 31 -> 33 x 33\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.ConvTranspose2d(8, 1, 2, 2, 1),  # 33 x 33 -> 64 x 64\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=4096, out_features=4096 * 2),\n",
    "            nn.Unflatten(1, (2, 4096)),\n",
    "            nn.LogSoftmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c60e0fe74851cb4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def reweight(cls_num_list, beta=0.9999):\n",
    "    per_cls_weights = torch.Tensor(\n",
    "        list(map(lambda n: (1 - beta) / (1 - beta**n), cls_num_list))\n",
    "    )\n",
    "    per_cls_weights *= len(cls_num_list) / per_cls_weights.sum()\n",
    "    return per_cls_weights\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, gamma=0.0):\n",
    "        super().__init__()\n",
    "        assert gamma >= 0\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return F.cross_entropy(\n",
    "            (1 - F.softmax(input, dim=1)) ** self.gamma * F.log_softmax(input, dim=1),\n",
    "            target,\n",
    "            weight=self.weight,\n",
    "        )\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "722007b7d35c4c88"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# parameters\n",
    "BATCH_SIZE=256\n",
    "FEATURES = [\n",
    "    \"elevation\",\n",
    "    \"th\",\n",
    "    \"vs\",\n",
    "    \"tmmn\",\n",
    "    \"tmmx\",\n",
    "    \"sph\",\n",
    "    \"pr\",\n",
    "    \"pdsi\",\n",
    "    \"NDVI\",\n",
    "    \"population\",\n",
    "    \"erc\",\n",
    "    \"PrevFireMask\",\n",
    "]\n",
    "LABELS = [\"FireMask\"]\n",
    "\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-2\n",
    "\n",
    "ARR_SIZE = 4096\n",
    "LENGTH, WIDTH = 64, 64"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b50492fbd79c1a43",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "num_classes = 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a69e6c6597cb239",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# set up data directory\n",
    "data_dir = os.path.join(os.path.abspath(\".\"), \"data\")\n",
    "Path(data_dir).mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff2dfb72661e35c3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# download data zip\n",
    "data_zip = os.path.join(data_dir, \"archive.zip\")\n",
    "if not os.path.exists(data_zip):\n",
    "    url = \"https://www.kaggle.com/api/v1/datasets/download/fantineh/next-day-wildfire-spread\"\n",
    "    urllib.request.urlretrieve(url, data_zip)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d79e8f47ff6e7119",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# extract files from zip\n",
    "files = defaultdict(list)\n",
    "file_types = [\"eval\", \"train\", \"test\"]\n",
    "with ZipFile(data_zip, \"r\") as z:\n",
    "    for file in z.namelist():\n",
    "        for file_type in file_types:\n",
    "            if file_type in file:\n",
    "                files[file_type].append(Path(file).stem)\n",
    "        if not os.path.exists(os.path.join(data_dir, file)):\n",
    "            z.extract(file, data_dir)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f42ab0a55cc1f34",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get all records into a data loader\n",
    "from torch.utils.data import default_collate\n",
    "def collate_fn(batch):\n",
    "    batch = [b for b in batch if (-1 not in b['PrevFireMask']) and (-1  not in b['FireMask'])]\n",
    "    return default_collate(batch)\n",
    "\n",
    "def get_loader_from_file_type(files: list,  record_path: str, file_types: list):\n",
    "    f = [file for file_type in file_types for file in files[file_type]]\n",
    "    dataset = MultiTFRecordDataset(\n",
    "        tfrecord_path, \n",
    "        None, \n",
    "        splits={file: 1.0 for file in f},\n",
    "        infinite=False\n",
    "    )\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "    return loader\n",
    "\n",
    "tfrecord_path = os.path.join(data_dir, \"{}.tfrecord\")\n",
    "train_loader = get_loader_from_file_type(files, tfrecord_path, [\"train\"])\n",
    "test_loader = get_loader_from_file_type(files, tfrecord_path, [\"test\", \"eval\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80f91b40cc4b05ca",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, test_losses):\n",
    "    plt.plot(range(1, len(train_losses)+1), train_losses, label=\"Train Loss\")\n",
    "    plt.plot(range(1, len(test_losses)+1), test_losses, label=\"Test Loss\")\n",
    "    plt.xticks(range(1, len(train_losses)+1))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11c5f884cb10a2d2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = next(iter(train_loader))\n",
    "print(data['FireMask'].shape)\n",
    "\n",
    "data = next(iter(test_loader))\n",
    "print(data['FireMask'].shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cbb6725e7f7f1a0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_dataset_items(data, item_list, length=LENGTH, width=WIDTH):\n",
    "    items = torch.cat([data[key][:, None, :] for key in item_list], dim=1)\n",
    "    items = items.reshape(items.shape[0], items.shape[1], length, width)\n",
    "    return items"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec455236b49dab19",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# gather batch of features\n",
    "features = get_dataset_items(data, FEATURES)\n",
    "labels = get_dataset_items(data, LABELS)\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "405d5a1b7dad2da8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def make_rcnn_target(labels: list[torch.Tensor], n_boxes=2, l=64, w=64, label_function=torch.max):\n",
    "    \"\"\"\n",
    "    length and width should be divisible evenly by n\n",
    "    i.e., 64x64 image can have 2, 4, 8, etc. evenly spaced boxes\n",
    "    \n",
    "    Create list of dict, each containing box bounds and corresponding labels for the boxes\n",
    "    Number of boxes is in one side of the resulting square, i.e., boxes=2 makes 4 boxes, boxes=4 makes 16 boxes\n",
    "    Label function determines how the label is computed, usually either the max or mode of the box's area\n",
    "    \"\"\"\n",
    "    assert l%n_boxes==0\n",
    "    assert w%n_boxes==0\n",
    "    \n",
    "    x_step = int(l/n_boxes)\n",
    "    y_step = int(w/n_boxes)\n",
    "    targets = []\n",
    "    \n",
    "    for label in labels:\n",
    "        boxes = torch.zeros((n_boxes**2, 4))\n",
    "        target_labels = torch.zeros((n_boxes**2)).type(torch.int64)\n",
    "        for x in range(n_boxes):\n",
    "            for y in range(n_boxes):\n",
    "                boxes[x*n_boxes+y]=torch.Tensor([[x*x_step, y*y_step, (x+1)*x_step-1, (y+1)*y_step-1]])\n",
    "                target_labels[x*n_boxes+y]=torch.Tensor(\n",
    "                    [label_function(label[0, x*x_step:(x+1)*x_step, y*y_step:(y+1)*y_step])]\n",
    "                 )\n",
    "        \n",
    "        targets.append({\"boxes\": boxes, \"labels\": target_labels})\n",
    "    return targets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b9d3be5ea40e21a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train(model, rcnn, loader, optimizer, n=None, n_boxes=2):\n",
    "    model.train()\n",
    "    rcnn.train()\n",
    "    total_loss = 0\n",
    "    for i, data in enumerate(loader):\n",
    "        if n is None:\n",
    "            n = len(data)\n",
    "        features = get_dataset_items(data, FEATURES)[0:n]\n",
    "        labels = get_dataset_items(data, LABELS)[0:n]\n",
    "        weights = model(features)\n",
    "        target = make_rcnn_target(labels, n_boxes=n_boxes)\n",
    "        loss = rcnn(weights, target)[\"loss_classifier\"]\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # if i % 100 == 0:\n",
    "        loss_val, current = loss.item(), i * BATCH_SIZE + len(features)\n",
    "        total_loss += loss_val\n",
    "    print(f\"Train loss: {total_loss:>7f}\")\n",
    "    return loss, features, labels, weights, total_loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69f782dd41462bd9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def test(model, rcnn, loader, n=None):\n",
    "    model.eval()\n",
    "    rcnn.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "    # output = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(loader):\n",
    "            if n is None:\n",
    "                n = len(data)\n",
    "            features = get_dataset_items(data, FEATURES)[0:n]\n",
    "            labels = get_dataset_items(data, LABELS)[0:n]\n",
    "            # Compute prediction and loss\n",
    "            weights = model(features)\n",
    "            output = rcnn(weights)\n",
    "    return output, features, labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed76d2855c1f53e0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_test_loss(model, rcnn, loader, n=None, n_boxes=2):\n",
    "    \"\"\"Hacky workaround to get test losses for RCNN\"\"\"\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "    rcnn.train()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(loader):\n",
    "            if n is None:\n",
    "                n = len(data)\n",
    "            features = get_dataset_items(data, FEATURES)[0:n]\n",
    "            labels = get_dataset_items(data, LABELS)[0:n]\n",
    "            target = make_rcnn_target(labels, n_boxes=n_boxes)\n",
    "\n",
    "            # Compute prediction and loss\n",
    "            weights = model(features)\n",
    "            loss = rcnn(weights, target)\n",
    "            total_loss+=loss['loss_classifier'].item()\n",
    "    print(f\"Test loss: {total_loss:>7f}\")\n",
    "    return loss, total_loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60d2ca12b759a9f5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from models.cnn import CNN\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "\n",
    "model = CNN()\n",
    "rcnn = fasterrcnn_resnet50_fpn(num_classes=num_classes, progress=True)\n",
    "\n",
    "model.to(device)\n",
    "rcnn.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "for t in range(EPOCHS):\n",
    "    print(f'Epoch {t+1}\\n')\n",
    "    _, _, _, weights, train_loss = train(model, rcnn, train_loader, optimizer, n_boxes=4)\n",
    "    pred, features, labels = test(model, rcnn, test_loader)\n",
    "    _, test_loss = calculate_test_loss(model, rcnn, test_loader, n_boxes=4)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "plot_losses(train_losses, test_losses)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ebf3dc8e32ef5ed",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# visualize features and labels\n",
    "\n",
    "rows = 5\n",
    "cols = 14\n",
    "CMAP = colors.ListedColormap(['black', 'silver', 'orangered'])\n",
    "BOUNDS = [-1, -0.1, 0.001, 1]\n",
    "NORM = colors.BoundaryNorm(BOUNDS, CMAP.N)\n",
    "\n",
    "TITLES = [\n",
    "    'Elevation',\n",
    "    'Wind Direction',\n",
    "    'Wind Velocity',\n",
    "    'Min Temperature',\n",
    "    'Max Temperature',\n",
    "    'Humidity',\n",
    "    'Precip',\n",
    "    'Drought',\n",
    "    'Vegetation',\n",
    "    'Population Density',\n",
    "    'Energy Release Component',\n",
    "    'Previous Fire Mask',\n",
    "    'True Fire Mask',\n",
    "    'Predicted Fire Mask',\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c48db28b47459eb0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6.5))\n",
    "fig.suptitle(\"Visualizations\", fontsize=20)\n",
    "# samples\n",
    "for i in range(rows):\n",
    "    # features and labels\n",
    "    plots = torch.cat((features[i], labels[i]), dim=0)\n",
    "    for j, plot in enumerate(plots):\n",
    "        plot = plot.detach().numpy()\n",
    "        plt.subplot(rows, cols, i*cols+j+1)\n",
    "        if i==0:\n",
    "            title = TITLES[j].replace(' ', '\\n')\n",
    "            plt.title(title)\n",
    "        if j >= cols-3:\n",
    "            plt.imshow(plot, cmap=CMAP, norm=NORM)\n",
    "        else:\n",
    "            plt.imshow(plot, cmap='viridis')   \n",
    "        plt.axis('off')\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4f7944656649e38",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        print(np.asarray(img).shape)\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "BOXES = 5\n",
    "for i in range(rows):\n",
    "    boxed = draw_bounding_boxes(labels[i], pred[i]['boxes'][0:BOXES])\n",
    "    show(boxed)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77e9f501459e637b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Encoder-Decoder with Focal Loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41ee30029ee366a4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get class counts\n",
    "class_counts = torch.zeros(2)\n",
    "for data in iter(train_loader):\n",
    "    label_batch = get_dataset_items(data, LABELS)\n",
    "    n_classes = label_batch.unique(return_counts=True)[1]\n",
    "    class_counts += n_classes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a01bed5f36de3206",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from models.focal_loss import reweight\n",
    "per_class_weights = reweight(class_counts, beta=.999999).to(device)\n",
    "print(per_class_weights)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e60fed1dba128c3c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train(model, loss_fn, loader, optimizer, n=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, data in enumerate(loader):\n",
    "        if n is None:\n",
    "            n = len(data)        \n",
    "        features = get_dataset_items(data, FEATURES)[0:n]\n",
    "        labels = get_dataset_items(data, LABELS)[0:n]\n",
    "        \n",
    "        pred = model(features)\n",
    "        \n",
    "        _pred = torch.flatten(torch.flatten(pred, 2).transpose(0, 1), 1).transpose(0, 1)\n",
    "        _labels =torch.flatten(labels).long()\n",
    "\n",
    "        loss = loss_fn(_pred, _labels)\n",
    "            \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # if i % 100 == 0:\n",
    "        loss_val, current = loss.item(), i * BATCH_SIZE + len(features)\n",
    "        total_loss += loss_val\n",
    "        break\n",
    "    print(f\"Train loss: {total_loss:>7f}\")    \n",
    "    return loss, features, labels, total_loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a62043068b893e8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def test(model, loss_fn, loader, n=None):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "    all_pred = []\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(loader):\n",
    "            if n is None:\n",
    "                n = len(data)\n",
    "            features = get_dataset_items(data, FEATURES)[0:n]\n",
    "            labels = get_dataset_items(data, LABELS)[0:n]\n",
    "            # Compute prediction and loss\n",
    "            pred = model(features)\n",
    "            _pred = torch.flatten(torch.flatten(pred, 2).transpose(0, 1), 1).transpose(0, 1)\n",
    "            _labels =torch.flatten(labels).long()\n",
    "            \n",
    "            loss = loss_fn(_pred, _labels)\n",
    "            total_loss += loss.item()\n",
    "            all_pred.append(pred)\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels)\n",
    "            break\n",
    "    print(f\"Test loss: {total_loss:>7f}\")\n",
    "    return all_pred, all_features, all_labels, total_loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9586347f79366cdb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from models.encoder_decoder import ConvoAE\n",
    "# from models.focal_loss import FocalLoss\n",
    "model = ConvoAE()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = FocalLoss(weight=per_class_weights)\n",
    "\n",
    "train_losses=[]\n",
    "test_losses=[]\n",
    "\n",
    "for t in range(EPOCHS):\n",
    "    print(f'Epoch {t+1}\\n')                                            \n",
    "    loss, features, labels, train_loss = train(model, loss_fn, train_loader, optimizer)\n",
    "    test_pred, test_features, test_labels, test_loss = test(model, loss_fn, test_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "plot_losses(train_losses, test_losses)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "117c8a8d76168c20",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6.5))\n",
    "fig.suptitle(\"Visualizations\", fontsize=20)\n",
    "# samples\n",
    "features = test_features[0]\n",
    "labels = test_labels[0]\n",
    "pred = test_pred[0]\n",
    "for i in range(rows):\n",
    "    # features and labels\n",
    "    \n",
    "    pred = pred.argmax(1, keepdim=True).reshape(pred.shape[0], 1, LENGTH, WIDTH)\n",
    "\n",
    "    plots = torch.cat((features[i], labels[i], pred[i]), dim=0)\n",
    "    for j, plot in enumerate(plots):\n",
    "        plot = plot.detach().numpy()\n",
    "        plt.subplot(rows, cols, i*cols+j+1)\n",
    "        if i==0:\n",
    "            title = TITLES[j].replace(' ', '\\n')\n",
    "            plt.title(title)\n",
    "        if j >= cols-3:\n",
    "            plt.imshow(plot, cmap=CMAP, norm=NORM)\n",
    "        else:\n",
    "            plt.imshow(plot, cmap='viridis')   \n",
    "        plt.axis('off')\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "616a185a44e2e3ff",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
