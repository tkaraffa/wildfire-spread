{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "import urllib.request\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from tfrecord.torch.dataset import MultiTFRecordDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# parameters\n",
    "BATCH_SIZE=256\n",
    "FEATURES = [\n",
    "    \"elevation\",\n",
    "    \"th\",\n",
    "    \"vs\",\n",
    "    \"tmmn\",\n",
    "    \"tmmx\",\n",
    "    \"sph\",\n",
    "    \"pr\",\n",
    "    \"pdsi\",\n",
    "    \"NDVI\",\n",
    "    \"population\",\n",
    "    \"erc\",\n",
    "    \"PrevFireMask\",\n",
    "]\n",
    "LABELS = [\"FireMask\"]\n",
    "\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-2\n",
    "\n",
    "ARR_SIZE = 4096\n",
    "LENGTH, WIDTH = 64, 64"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b50492fbd79c1a43",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "num_classes = 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a69e6c6597cb239",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# set up data directory\n",
    "data_dir = os.path.join(os.path.abspath(\".\"), \"data\")\n",
    "Path(data_dir).mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff2dfb72661e35c3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# download data zip\n",
    "data_zip = os.path.join(data_dir, \"archive.zip\")\n",
    "if not os.path.exists(data_zip):\n",
    "    url = \"https://www.kaggle.com/api/v1/datasets/download/fantineh/next-day-wildfire-spread\"\n",
    "    urllib.request.urlretrieve(url, data_zip)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d79e8f47ff6e7119",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# extract files from zip\n",
    "files = defaultdict(list)\n",
    "file_types = [\"eval\", \"train\", \"test\"]\n",
    "with ZipFile(data_zip, \"r\") as z:\n",
    "    for file in z.namelist():\n",
    "        for file_type in file_types:\n",
    "            if file_type in file:\n",
    "                files[file_type].append(Path(file).stem)\n",
    "        if not os.path.exists(os.path.join(data_dir, file)):\n",
    "            z.extract(file, data_dir)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f42ab0a55cc1f34",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get all records into a data loader\n",
    "def get_loader_from_file_type(files: list,  record_path: str, file_types: list):\n",
    "    f = [file for file_type in file_types for file in files[file_type]]\n",
    "    dataset = MultiTFRecordDataset(\n",
    "        tfrecord_path, \n",
    "        None, \n",
    "        splits={file: 1.0 for file in f},\n",
    "        infinite=False\n",
    "    )\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    return loader\n",
    "\n",
    "tfrecord_path = os.path.join(data_dir, \"{}.tfrecord\")\n",
    "train_loader = get_loader_from_file_type(files, tfrecord_path, [\"train\"])\n",
    "test_loader = get_loader_from_file_type(files, tfrecord_path, [\"test\", \"eval\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80f91b40cc4b05ca",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = next(iter(train_loader))\n",
    "print(data['FireMask'].shape)\n",
    "\n",
    "data = next(iter(test_loader))\n",
    "print(data['FireMask'].shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cbb6725e7f7f1a0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_dataset_items(data, item_list, length=LENGTH, width=WIDTH):\n",
    "    items = torch.cat([data[key][:, None, :] for key in item_list], dim=1)\n",
    "    items = items.reshape(items.shape[0], items.shape[1], length, width)\n",
    "    return items"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec455236b49dab19",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# gather batch of features\n",
    "features = get_dataset_items(data, FEATURES)\n",
    "labels = get_dataset_items(data, LABELS)\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "405d5a1b7dad2da8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def make_rcnn_target(labels: list[torch.Tensor], n_boxes=2, l=64, w=64, label_function=torch.max):\n",
    "    \"\"\"\n",
    "    length and width should be divisible evenly by n\n",
    "    i.e., 64x64 image can have 2, 4, 8, etc. evenly spaced boxes\n",
    "    \n",
    "    Create list of dict, each containing box bounds and corresponding labels for the boxes\n",
    "    Number of boxes is in one side of the resulting square, i.e., boxes=2 makes 4 boxes, boxes=4 makes 16 boxes\n",
    "    Label function determines how the label is computed, usually either the max or mode of the box's area\n",
    "    \"\"\"\n",
    "    assert l%n_boxes==0\n",
    "    assert w%n_boxes==0\n",
    "    \n",
    "    x_step = int(l/n_boxes)\n",
    "    y_step = int(w/n_boxes)\n",
    "    targets = []\n",
    "    \n",
    "    for label in labels:\n",
    "        boxes = torch.zeros((n_boxes**2, 4))\n",
    "        target_labels = torch.zeros((n_boxes**2)).type(torch.int64)\n",
    "        for x in range(n_boxes):\n",
    "            for y in range(n_boxes):\n",
    "                boxes[x*2+y]=torch.Tensor([[x*x_step, y*y_step, (x+1)*x_step-1, (y+1)*y_step-1]])\n",
    "                target_labels[x*2+y]=torch.Tensor(\n",
    "                    [label_function(label[0, x*x_step:(x+1)*x_step, y*y_step:(y+1)*y_step])]\n",
    "                 )\n",
    "        \n",
    "        targets.append({\"boxes\": boxes, \"labels\": target_labels})\n",
    "    return targets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b9d3be5ea40e21a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train(model, rcnn, loader, optimizer, n=None, n_boxes=2):\n",
    "    model.train()\n",
    "    rcnn.train()\n",
    "    total_loss = 0\n",
    "    for i, data in enumerate(loader):\n",
    "        if n is None:\n",
    "            n = len(data)\n",
    "        features = get_dataset_items(data, FEATURES)[0:n]\n",
    "        labels = get_dataset_items(data, LABELS)[0:n]\n",
    "        weights = model(features)\n",
    "        target = make_rcnn_target(labels, n_boxes=n_boxes)\n",
    "        loss = rcnn(weights, target)[\"loss_classifier\"]\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # if i % 100 == 0:\n",
    "        loss_val, current = loss.item(), i * BATCH_SIZE + len(features)\n",
    "        total_loss += loss_val\n",
    "    print(f\"Train loss: {total_loss:>7f}\")\n",
    "    return loss, features, labels, weights"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69f782dd41462bd9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def test(model, rcnn, loader, n=None):\n",
    "    model.eval()\n",
    "    rcnn.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "    # output = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(loader):\n",
    "            if n is None:\n",
    "                n = len(data)\n",
    "            features = get_dataset_items(data, FEATURES)[0:n]\n",
    "            labels = get_dataset_items(data, LABELS)[0:n]\n",
    "            # Compute prediction and loss\n",
    "            weights = model(features)\n",
    "            output = rcnn(weights)\n",
    "    return output, features, labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed76d2855c1f53e0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_test_loss(model, rcnn, loader, n=None, n_boxes=2):\n",
    "    \"\"\"Hacky workaround to get test losses for RCNN\"\"\"\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "    rcnn.train()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(loader):\n",
    "            if n is None:\n",
    "                n = len(data)\n",
    "            features = get_dataset_items(data, FEATURES)[0:n]\n",
    "            labels = get_dataset_items(data, LABELS)[0:n]\n",
    "            target = make_rcnn_target(labels, n_boxes=n_boxes)\n",
    "\n",
    "            # Compute prediction and loss\n",
    "            weights = model(features)\n",
    "            loss = rcnn(weights, target)\n",
    "            total_loss+=loss['loss_classifier'].item()\n",
    "    print(f\"Test loss: {total_loss:>7f}\")\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60d2ca12b759a9f5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from models.cnn import CNN\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "\n",
    "model = CNN()\n",
    "rcnn = fasterrcnn_resnet50_fpn(num_classes=num_classes, progress=True)\n",
    "\n",
    "model.to(device)\n",
    "rcnn.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for t in range(EPOCHS):\n",
    "    print(f'Epoch {t+1}\\n')\n",
    "    _, _, _, weights = train(model, rcnn, train_loader, optimizer, n_boxes=4)\n",
    "    pred, features, labels = test(model, rcnn, test_loader)\n",
    "    calculate_test_loss(model, rcnn, test_loader, n_boxes=4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ebf3dc8e32ef5ed",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# visualize features and labels\n",
    "\n",
    "rows = 5\n",
    "cols = 14\n",
    "CMAP = colors.ListedColormap(['black', 'silver', 'orangered'])\n",
    "BOUNDS = [-1, -0.1, 0.001, 1]\n",
    "NORM = colors.BoundaryNorm(BOUNDS, CMAP.N)\n",
    "\n",
    "TITLES = [\n",
    "    'Elevation',\n",
    "    'Wind Direction',\n",
    "    'Wind Velocity',\n",
    "    'Min Temperature',\n",
    "    'Max Temperature',\n",
    "    'Humidity',\n",
    "    'Precip',\n",
    "    'Drought',\n",
    "    'Vegetation',\n",
    "    'Population Density',\n",
    "    'Energy Release Component',\n",
    "    'Previous Fire Mask',\n",
    "    'True Fire Mask',\n",
    "    'Predicted Fire Mask',\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c48db28b47459eb0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6.5))\n",
    "fig.suptitle(\"Visualizations\", fontsize=20)\n",
    "# samples\n",
    "for i in range(rows):\n",
    "    # features and labels\n",
    "    plots = torch.cat((features[i], labels[i]), dim=0)\n",
    "    for j, plot in enumerate(plots):\n",
    "        plot = plot.detach().numpy()\n",
    "        plt.subplot(rows, cols, i*cols+j+1)\n",
    "        if i==0:\n",
    "            title = TITLES[j].replace(' ', '\\n')\n",
    "            plt.title(title)\n",
    "        if j >= cols-3:\n",
    "            plt.imshow(plot, cmap=CMAP, norm=NORM)\n",
    "        else:\n",
    "            plt.imshow(plot, cmap='viridis')   \n",
    "        plt.axis('off')\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4f7944656649e38",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        print(np.asarray(img).shape)\n",
    "        # axs[0, i].text(*np.asarray(img)[0, -1], \"test\")\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "BOXES = 5\n",
    "for i in range(rows):\n",
    "    boxed = draw_bounding_boxes(labels[i], pred[i]['boxes'][0:BOXES])\n",
    "    show(boxed)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77e9f501459e637b",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
